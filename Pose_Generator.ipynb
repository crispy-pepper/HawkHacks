{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Oat_M\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from IPython.display import Video\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width = 1280\n",
      "Height = 720\n"
     ]
    }
   ],
   "source": [
    "from win32api import GetSystemMetrics\n",
    "w =  GetSystemMetrics(0)\n",
    "h = GetSystemMetrics(1)\n",
    "print(\"Width =\", GetSystemMetrics(0))\n",
    "print(\"Height =\", GetSystemMetrics(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "numPoses = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0) # video capture source camera (Here webcam of laptop) \n",
    "\n",
    "while True: \n",
    "\n",
    "    ret,frame = cap.read() # return a single frame in variable `frame`\n",
    "\n",
    "    # Create a MediaPipe `Pose` object\n",
    "    with mp_pose.Pose(static_image_mode=True, \n",
    "            model_complexity=2,\n",
    "                    enable_segmentation=True) as pose:\n",
    "            \n",
    "        # Read the file in and get dims\n",
    "        #image = cv2.imread(frame)\n",
    "        #display(image)\n",
    "\n",
    "        # Convert the BGR image to RGB and then process with the `Pose` object.\n",
    "        results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "    # Copy the image\n",
    "    segmented_image = frame.copy()\n",
    "\n",
    "    # Probability threshold in [0, 1] that says how \"tight\" to make the segmentation. Greater value => tighter.\n",
    "    tightness = 0.3\n",
    "\n",
    "    # Stack the segmentation mask for 3 RGB channels, and then create a filter for which pixels to keep\n",
    "\n",
    "    if np.stack((results.segmentation_mask,) * 3, axis=-1).any() == None: \n",
    "        continue\n",
    "\n",
    "    condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > tightness\n",
    "\n",
    "    # Creates a black background image\n",
    "    bg_image = np.zeros(frame.shape, dtype=np.uint8)\n",
    "    figure = np.zeros(frame.shape, dtype=np.uint8)\n",
    "\n",
    "    # Can change the color of this background by specifying (0-255) RGB values. We choose green-screen green.\n",
    "    bg_image[:] = [255, 255, 255]\n",
    "    figure[:] = [0, 0, 0]\n",
    "\n",
    "    # For every pixel location, display the corresponding pixel from the original imgae if the condition in our filter is met (i.e. the probability of being part of the object is above the inclusiogn threshold), or else display corresponding pixel from the background array (i.e. green)\n",
    "    segmented_image = np.where(condition, figure, bg_image)\n",
    "    segmented_image = cv2.resize(segmented_image, (w,h))\n",
    "    \n",
    "    cv2.imshow(\"pose\", segmented_image)\n",
    "    path = \"C:\\Computer\\Programming\\opencv\\c\\poses\"\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            cap = None\n",
    "            break\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('y'): #save on pressing 'y' \n",
    "\n",
    "        if numPoses < 1: \n",
    "            numPoses += 1\n",
    "\n",
    "            filename = f\"pose{numPoses}.jpg\"\n",
    "\n",
    "            cv2.imwrite(os.path.join(path , filename), segmented_image)\n",
    "\n",
    "        else: \n",
    "            cv2.destroyAllWindows()\n",
    "            cap = None\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

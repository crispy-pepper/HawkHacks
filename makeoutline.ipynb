{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import PyQt5\n",
    "#from PIL import img\n",
    "from IPython.display import Video\n",
    "import nb_helpers\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_pose = mp.solutions.pose\n",
    "#mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "mpDraw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width = 1280\n",
      "Height = 720\n"
     ]
    }
   ],
   "source": [
    "from win32api import GetSystemMetrics\n",
    "w =  GetSystemMetrics(0)\n",
    "h = GetSystemMetrics(1)\n",
    "print(\"Width =\", GetSystemMetrics(0))\n",
    "print(\"Height =\", GetSystemMetrics(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 't.jpg'\n",
    "\n",
    "# Create a MediaPipe `Pose` object\n",
    "with mp_pose.Pose(static_image_mode=True, \n",
    "\t\t  model_complexity=2,\n",
    "                  enable_segmentation=True) as pose:\n",
    "        \n",
    "    # Read the file in and get dims\n",
    "    image = cv2.imread(file)\n",
    "    #display(image)\n",
    "\n",
    "    # Convert the BGR image to RGB and then process with the `Pose` object.\n",
    "    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the image\n",
    "segmented_image = image.copy()\n",
    "\n",
    "# Probability threshold in [0, 1] that says how \"tight\" to make the segmentation. Greater value => tighter.\n",
    "tightness = .3\n",
    "\n",
    "# Stack the segmentation mask for 3 RGB channels, and then create a filter for which pixels to keep\n",
    "condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > tightness\n",
    "\n",
    "# Creates a black background image\n",
    "bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "figure = np.zeros(image.shape, dtype=np.uint8)\n",
    "\n",
    "# Can change the color of this background by specifying (0-255) RGB values. We choose green-screen green.\n",
    "bg_image[:] = [0, 0, 0]\n",
    "figure[:] = [255, 255, 255]\n",
    "\n",
    "# For every pixel location, display the corresponding pixel from the original imgae if the condition in our filter is met (i.e. the probability of being part of the object is above the inclusiogn threshold), or else display corresponding pixel from the background array (i.e. green)\n",
    "segmented_image = np.where(condition, figure, bg_image)\n",
    "\n",
    "filename = \"tgreen.jpg\"\n",
    "cv2.imwrite(filename, segmented_image)\n",
    "seg = cv2.imread(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m curTime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     12\u001b[0m success, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 14\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(img, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#imgPlayer = np.zeros((512,512,3), np.uint8)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#imgPlayer = cv2.resize(imgPlayer, (w,h))\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "pTime = 0\n",
    "while True:\n",
    "    #print(\"Running\")\n",
    "\n",
    "    landDetected = True\n",
    "\n",
    "    inArea = True\n",
    "\n",
    "    curTime = time.time()\n",
    "\n",
    "    success, img = cap.read()\n",
    "\n",
    "    img = cv2.resize(img, (w,h))\n",
    "    img = cv2.flip(img, 1)\n",
    "\n",
    "    #imgPlayer = np.zeros((512,512,3), np.uint8)\n",
    "    #imgPlayer = cv2.resize(imgPlayer, (w,h))\n",
    "\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imgRGB)\n",
    "\n",
    "    segmented_img = img.copy()\n",
    "\n",
    "    # Probability threshold in [0, 1] that says how \"tight\" to make the segmentation. Greater value => tighter.\n",
    "    tightness = .3\n",
    "\n",
    "    # Stack the segmentation mask for 3 RGB channels, and then create a filter for which pixels to keep\n",
    "    condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > tightness\n",
    "\n",
    "    # Creates a black background img\n",
    "    bg_img = np.zeros(img.shape, dtype=np.uint8)\n",
    "\n",
    "    # Can change the color of this background by specifying (0-255) RGB values. We choose green-screen green.\n",
    "    bg_img[:] = [4, 244, 4]\n",
    "\n",
    "    # For every pixel location, display the corresponding pixel from the original imgae if the condition in our filter is met (i.e. the probability of being part of the object is above the inclusiogn threshold), or else display corresponding pixel from the background array (i.e. green)\n",
    "    segmented_img = np.where(condition, segmented_img, bg_img)\n",
    "\n",
    "    filename = \"pose_green_screen.png\"\n",
    "    cv2.imshow(\"Image Player\", segmented_img)\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_img = img.copy()\n",
    "\n",
    "# Probability threshold in [0, 1] that says how \"tight\" to make the segmentation. Greater value => tighter.\n",
    "tightness = .3\n",
    "\n",
    "# Stack the segmentation mask for 3 RGB channels, and then create a filter for which pixels to keep\n",
    "condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > tightness\n",
    "\n",
    "# Creates a black background img\n",
    "bg_img = np.zeros(img.shape, dtype=np.uint8)\n",
    "\n",
    "# Can change the color of this background by specifying (0-255) RGB values. We choose green-screen green.\n",
    "bg_img[:] = [4, 244, 4]\n",
    "\n",
    "# For every pixel location, display the corresponding pixel from the original imgae if the condition in our filter is met (i.e. the probability of being part of the object is above the inclusiogn threshold), or else display corresponding pixel from the background array (i.e. green)\n",
    "segmented_img = np.where(condition, segmented_img, bg_img)\n",
    "\n",
    "filename = \"pose_green_screen.png\"\n",
    "cv2.imwrite(filename, segmented_img)\n",
    "display(img.open(filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
